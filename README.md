1. IntroducciÃ³n
Este informe documenta el desarrollo y despliegue de una API Flask que utiliza un modelo de clasificaciÃ³n para predecir el diagnÃ³stico de cÃ¡ncer de mama utilizando el dataset Breast Cancer Wisconsin disponible en scikit-learn. El proyecto fue construido como parte de la evaluaciÃ³n modular del mÃ³dulo de Machine Learning.
2. Estructura del Proyecto
El proyecto se estructura de la siguiente manera:
â”œâ”€â”€ app.py # CÃ³digo principal de la API Flask â”œâ”€â”€ Dockerfile # ConfiguraciÃ³n para contenedor Docker â”œâ”€â”€ modelo_cancer.pkl # Modelo entrenado y serializado â”œâ”€â”€ requirements.txt # Dependencias exactas del proyecto â”œâ”€â”€ test_api.py # Script para realizar pruebas locales a la API â”œâ”€â”€ .github/workflows # ConfiguraciÃ³n de CI/CD con GitHub Actions â””â”€â”€ train_model.py # Script para entrenar el modelo (no utilizado en producciÃ³n)
3. CI/CD con GitHub y Render
Se configurÃ³ integraciÃ³n continua (CI/CD) mediante GitHub Actions. Cada vez que se hace push al repositorio, Render reconstruye y despliega automÃ¡ticamente la API. Se fijaron versiones especÃ­ficas de las librerÃ­as para evitar incompatibilidades al cargar el modelo.
4. Pruebas de PredicciÃ³n
Se realizaron pruebas exitosas mediante curl. Ejemplos:
â€¢ PredicciÃ³n Benigna (0):
curl -X POST https://evaluacion-modular-flask-cancer-api3.onrender.com/predict -H "Content-Type: application/json" -d "{"features": [20.29, 14.34, 135.1, 1297.0, 0.1003, 0.1328, 0.198, 0.1043, 0.1809, 0.0588, 0.7572, 0.7813, 5.438, 94.44, 0.01149, 0.02461, 0.05688, 0.01885, 0.01756, 0.005115, 22.54, 16.67, 152.2, 1575.0, 0.1374, 0.205, 0.4, 0.1625, 0.2364, 0.07678]}"
â€¢ PredicciÃ³n Maligna (1):
curl -X POST https://evaluacion-modular-flask-cancer-api3.onrender.com/predict -H "Content-Type: application/json" -d "{"features": [13.54, 14.36, 87.46, 566.3, 0.09779, 0.08129, 0.06664, 0.04781, 0.1885, 0.05766, 0.2699, 0.7886, 2.058, 23.56, 0.008462, 0.0146, 0.02387, 0.01315, 0.0198, 0.0023, 15.11, 19.26, 99.7, 711.2, 0.144, 0.1773, 0.239, 0.1288, 0.2977, 0.07259]}"
5. ConclusiÃ³n
El proyecto fue desplegado exitosamente en Render.com con una API funcional y estable, utilizando CI/CD y versionado controlado. Se demostrÃ³ su funcionalidad mediante pruebas directas desde la lÃ­nea de comandos.
6. JustificaciÃ³n del Entorno de Despliegue y Monitoreo
Aunque la consigna sugerÃ­a el uso de plataformas como AWS, Azure o Google Cloud Platform, se optÃ³ por Render.com debido a su simplicidad, integraciÃ³n nativa con GitHub, y facilidad para desplegar APIs Flask sin necesidad de configurar mÃ¡quinas virtuales, buckets o entornos complejos. Esto permitiÃ³ un desarrollo Ã¡gil, centrado en el modelo y la API, sin desviar esfuerzos al mantenimiento de infraestructura compleja.
Render permite visualizar logs del contenedor en tiempo real desde el dashboard, facilitando el monitoreo bÃ¡sico de eventos, errores y peticiones. Aunque no ofrece herramientas de monitoreo avanzadas como CloudWatch o Azure Insights, es suficiente para proyectos de desarrollo, pruebas o formaciÃ³n.
AdemÃ¡s, Render simplifica enormemente el proceso de despliegue de APIs mediante Docker y GitHub Actions sin requerir configuraciones de red, permisos ni billing complejo. Esto lo hace especialmente adecuado para entornos acadÃ©micos, prototipos o proyectos individuales. A diferencia de AWS, GCP o Azure, no requiere configurar buckets, firewalls o roles IAM, lo que agiliza la curva de aprendizaje.
7. Monitoreo BÃ¡sico del Endpoint
El monitoreo se realizÃ³ desde el dashboard de Render.com. El panel de la aplicaciÃ³n muestra:
â€¢ â€¢ Logs del contenedor en tiempo real
â€¢ â€¢ Estado de despliegue actual (Ã©xito/error)
â€¢ â€¢ Historial de despliegues
AdemÃ¡s, se realizaron pruebas manuales usando curl para verificar la latencia y estabilidad del endpoint. Para una soluciÃ³n de producciÃ³n, se sugiere implementar Prometheus + Grafana o integrar servicios externos como UptimeRobot.
8. MÃ©tricas de Uso y DesempeÃ±o (Bonus)
Como parte del monitoreo bÃ¡sico, se establecieron las siguientes mÃ©tricas para evaluar el desempeÃ±o de la API:
â€¢ Latencia:
Se midiÃ³ usando Measure-Command en PowerShell con resultados entre 0.3 y 0.8 segundos por solicitud. El comando utilizado fue:
Measure-Command { Invoke-WebRequest -Uri "https://evaluacion-modular-flask-cancer-api3.onrender.com/predict" -Method POST -Body '{"features": [14.2, 20.0, 92.0, 640.0, 0.1, 0.15, 0.2, 0.08, 0.2, 0.06, 0.6, 1.0, 4.5, 50.0, 0.007, 0.025, 0.03, 0.01, 0.02, 0.004, 16.0, 27.0, 115.0, 800.0, 0.14, 0.3, 0.35, 0.12, 0.25, 0.08]}' -ContentType "application/json" }
â€¢ Frecuencia de uso:
Durante la fase de validaciÃ³n, se realizaron mÃ¡s de 10 solicitudes al endpoint `/predict`. La frecuencia de uso puede ampliarse en producciÃ³n mediante la integraciÃ³n de herramientas como UptimeRobot, Google Analytics API Gateway, o servicios como Postman Monitor.
En un entorno productivo, se recomienda almacenar logs de acceso con timestamps para construir dashboards que permitan visualizar uso horario, IPs, status codes y latencia individual.


9. Capturas de pantalla clave
ðŸ–¼ðŸ–¼ô€€€ 1. Estructura del Proyecto
ðŸ–¼ðŸ–¼ô€€€ 2. Repositorio en GitHub
ðŸ–¼ðŸ–¼ô€€€ 3. Deploy en Render
â€¢ Captura 1: ConfiguraciÃ³n del servicio (nombre, build command, start command).

â€¢ Captura 2: Logs en Render mostrando despliegue exitoso (Deploy succeeded).
â€¢ Captura 3: URL activa de la API y prueba en navegador o Postman.
ðŸ–¼ðŸ–¼ô€€€ 4. Pruebas de API
â€¢ Captura 1: curl desde CMD o PowerShell con respuesta {"prediction": 0} o 1.
â€¢ Captura 2 (bonus): EjecuciÃ³n de test_api.py mostrando el resultado de predicciÃ³n.
ðŸ–¼ðŸ–¼ô€€€ 5. Monitoreo y MÃ©tricas
â€¢ Captura: Logs en Render mostrando varias peticiones a /predict.
â€¢ Debe mostrar: Frecuencia de uso y tiempos de respuesta (latencia observada).
â€¢ Consola con Measure-Command o similar para medir latencia.
ðŸ–¼ðŸ–¼ô€€€ 6. Error Handling (opcional)
â€¢ Captura: Error controlado si se manda un payload incorrecto, mostrando un 400 o 415.
10. Mejoras Futuras o Escalabilidad
ðŸš€ðŸš€ Escalabilidad y Uso de Kubernetes (opcional)
Aunque el despliegue actual se realiza mediante Render.com, una plataforma sencilla y eficaz para proyectos pequeÃ±os o acadÃ©micos, en un entorno de producciÃ³n real serÃ­a recomendable migrar la API a un orquestador como Kubernetes.
Kubernetes permitirÃ­a:
â€¢ Escalar horizontalmente el servicio basado en demanda (Auto-scaling).
â€¢ Realizar despliegues canarios o blue-green para actualizaciones sin downtime.
â€¢ Gestionar mÃºltiples rÃ©plicas con balanceadores de carga.
â€¢ Integrar herramientas de monitoreo como Prometheus + Grafana para observar latencia, uso y errores.
Este tipo de despliegue se puede realizar en proveedores como Google Kubernetes Engine (GKE), Azure Kubernetes Service (AKS) o Amazon EKS, y es especialmente Ãºtil si se espera una alta carga de trÃ¡fico o mÃºltiples servicios relacionados con el modelo.
